{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# fastmri\n",
    "import fastmri\n",
    "from fastmri.data import subsample\n",
    "from fastmri.data import transforms, mri_data\n",
    "from fastmri.evaluate import ssim, psnr, nmse\n",
    "from fastmri.losses import SSIMLoss\n",
    "from fastmri.models import Unet\n",
    "\n",
    "# other\n",
    "from myutils import SSIM, PSNR\n",
    "from mymodels import VisionTransformer, ReconNet\n",
    "import os\n",
    "# Device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fastMRIDataset(Dataset):\n",
    "    def __init__(self, challenge, path, isval):\n",
    "        \"\"\"\n",
    "        Dataloader for 4x acceleration and random sampling\n",
    "        challenge: 'multicoil' or 'singlecoil'\n",
    "        path: path to dataset\n",
    "        isval: whether dataset is fastMRI's validation set or training set\n",
    "        \"\"\"\n",
    "        self.challenge = challenge \n",
    "        self.data_path = path\n",
    "        self.isval = isval\n",
    "\n",
    "        self.data = mri_data.SliceDataset(\n",
    "            root=self.data_path,\n",
    "            transform=self.data_transform,\n",
    "            challenge=self.challenge,\n",
    "            use_dataset_cache=True,\n",
    "            )\n",
    "\n",
    "        self.mask_func = subsample.RandomMaskFunc( # RandomMaskFunc for knee, EquispacedMaskFunc for brain\n",
    "            center_fractions=[0.08],\n",
    "            accelerations=[4],\n",
    "            )\n",
    "            \n",
    "    def data_transform(self, kspace, mask, target, data_attributes, filename, slice_num):\n",
    "        if self.isval:\n",
    "            seed = tuple(map(ord, filename))\n",
    "        else:\n",
    "            seed = None     \n",
    "        kspace = transforms.to_tensor(kspace)\n",
    "        masked_kspace, _ = transforms.apply_mask(kspace, self.mask_func, seed)        \n",
    "        \n",
    "        target = transforms.to_tensor(target)\n",
    "        zero_fill = fastmri.ifft2c(masked_kspace)\n",
    "        zero_fill = transforms.complex_center_crop(zero_fill, target.shape)   \n",
    "        x = fastmri.complex_abs(zero_fill)\n",
    "        \n",
    "        if self.challenge == 'multicoil':\n",
    "            x = fastmri.rss(x)\n",
    "\n",
    "        x = x.unsqueeze(0)\n",
    "        target = target.unsqueeze(0)\n",
    "        \n",
    "        return (x, target, data_attributes['max'])    \n",
    "\n",
    "    def __len__(self,):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "\n",
    "        return data\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please specifiy data path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "challenge = 'multicoil' # 'multicoil' or 'singlecoil'\n",
    "train_path = './traindata/' # path to fastmri's training data\n",
    "val_path = './valdata/' # path to fastmri's validation data\n",
    "dataset = fastMRIDataset(challenge=challenge, path=train_path, isval=False)\n",
    "val_dataset = fastMRIDataset(challenge=challenge, path=val_path, isval=True)\n",
    "\n",
    "ntrain = len(dataset) # number of training data\n",
    "train_dataset, _ = torch.utils.data.random_split(dataset, [ntrain, len(dataset)-ntrain], generator=torch.Generator().manual_seed(42))\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, generator=torch.Generator().manual_seed(42))\n",
    "valloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Init Model\"\"\"\n",
    "## Vision Transformer\n",
    "avrg_img_size = 340\n",
    "patch_size = 10\n",
    "depth = 10\n",
    "num_heads = 16\n",
    "embed_dim = 44\n",
    "\n",
    "net = VisionTransformer(\n",
    "    avrg_img_size=avrg_img_size, \n",
    "    patch_size=patch_size, \n",
    "    in_chans=1, embed_dim=embed_dim, \n",
    "    depth=depth, num_heads=num_heads,\n",
    "    )\n",
    "\n",
    "## Unet\n",
    "# net = Unet(\n",
    "#     in_chans=1,\n",
    "#     out_chans=1,\n",
    "#     chans=32,\n",
    "#     num_pool_layers=4,\n",
    "#     )\n",
    "\n",
    "model = ReconNet(net).to(device)\n",
    "\n",
    "print('#Params:', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate model\n",
    "def validate(model):\n",
    "    valloader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)   \n",
    "    model.eval()    \n",
    "    ssim_ = SSIM().to(device)\n",
    "    psnr_ = PSNR().to(device)\n",
    "    psnrs = []\n",
    "    ssims = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            inputs, targets, maxval = data        \n",
    "            outputs = model(inputs.to(device))\n",
    "            ssims.append(ssim_(outputs, targets.to(device), maxval.to(device)))\n",
    "            psnrs.append(psnr_(outputs, targets.to(device), maxval.to(device)))\n",
    "    \n",
    "    ssimval = torch.cat(ssims).mean()\n",
    "    \n",
    "    print(' Recon. PSNR: {:0.3f} pm {:0.2f}'.format(torch.cat(psnrs).mean(), 2*torch.cat(psnrs).std()))\n",
    "    print(' Recon. SSIM: {:0.4f} pm {:0.3f}'.format(torch.cat(ssims).mean(), 2*torch.cat(ssims).std()))\n",
    "                \n",
    "    return (1-ssimval).item()\n",
    "\n",
    "# Save model\n",
    "def save_model(path, model, train_hist, val_hist, optimizer, scheduler=None):\n",
    "    net = model.net\n",
    "    if scheduler:\n",
    "        checkpoint = {\n",
    "            'model' :  ReconNet(net),\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(), \n",
    "        }\n",
    "    else:\n",
    "        checkpoint = {\n",
    "            'model' :  ReconNet(net),\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }\n",
    "        \n",
    "    torch.save(train_hist, path + 'train_hist.pt')\n",
    "    torch.save(val_hist, path + 'val_hist.pt')    \n",
    "    torch.save(checkpoint,  path + 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Optimizer\"\"\"\n",
    "criterion = SSIMLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0)\n",
    "train_hist = []\n",
    "val_hist = []\n",
    "best_val = float(\"inf\")\n",
    "path = './' # Path for saving model checkpoint and loss history\n",
    "num_epochs = 40\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.0003,\n",
    "                                          total_steps=num_epochs, pct_start=0.1,\n",
    "                                          anneal_strategy='linear',\n",
    "                                          cycle_momentum=False,\n",
    "                                          base_momentum=0., max_momentum=0., div_factor=0.1*num_epochs, final_div_factor=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train Model\"\"\"\n",
    "for epoch in range(0, num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for data in trainloader:\n",
    "        inputs, targets, maxval = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to(device))\n",
    "        loss = criterion(outputs, targets.to(device), maxval.to(device))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1, norm_type=1.)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "        \n",
    "    train_hist.append(train_loss/len(trainloader))\n",
    "    print('Epoch {}, Train loss.: {:0.4f}'.format(epoch+1, train_hist[-1]))\n",
    "    \n",
    "    if (epoch+1)%5==0:\n",
    "        print('Validation:')\n",
    "        val_hist.append(validate(model))        \n",
    "        if val_hist[-1] < best_val:\n",
    "            save_model(path, model, train_hist, val_hist, optimizer, scheduler=scheduler)\n",
    "            best_val = val_hist[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"Loss History Plot\"\"\"\n",
    "plt.plot(range(1,len(train_hist)+1), train_hist, 'r+-')\n",
    "plt.plot(torch.linspace(5, len(train_hist), int(len(train_hist)/5)), val_hist, 'r*-')\n",
    "plt.grid('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from myutils import imshow\n",
    "\n",
    "\"\"\"Example reconstructions\"\"\"\n",
    "valloader = DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=0, generator=torch.Generator().manual_seed(0))\n",
    "dataiter = iter(valloader)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for k in range(0,5):    \n",
    "        inputs, targets, maxval = dataiter.next()\n",
    "        outputs = model(inputs.to(device)).cpu()\n",
    "        plt.figure(figsize=(15,7))\n",
    "        imshow(make_grid([inputs[0], outputs[0], targets[0], (targets[0]-outputs[0]).abs()],normalize = True, value_range=(0,maxval[0]/1.5)))\n",
    "        plt.axis('off')\n",
    "        img_input = inputs[0].numpy()\n",
    "        img_recon = outputs[0].numpy()\n",
    "        img = targets[0].numpy()\n",
    "        print(k+1)\n",
    "        print(' ssim:', ssim(img, img_recon, maxval[0].item()))\n",
    "        print('*ssim:', ssim(img, img_input, maxval[0].item()))\n",
    "        print(' psnr:', psnr(img, img_recon, maxval[0].item()))\n",
    "        print('*psnr:', psnr(img, img_input, maxval[0].item()))\n",
    "        print(' nmse:', nmse(img, img_recon, ))\n",
    "        print('*nmse:', nmse(img, img_input))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
